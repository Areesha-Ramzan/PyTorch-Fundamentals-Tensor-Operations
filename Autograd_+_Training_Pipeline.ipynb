{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "** 1.Create a tensor with requires_grad=True\n"
      ],
      "metadata": {
        "id": "KlHXJpzaq316"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "INICODiynHgl"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor(5.0,requires_grad=True)"
      ],
      "metadata": {
        "id": "hp8DF5Y-n-Gm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I created a tensor x using PyTorch and set requires_grad=True. This tells PyTorch to keep track of all the operations done using x, so later it can compute the derivative (gradient) of any result that comes from it."
      ],
      "metadata": {
        "id": "H7W2zQff0_7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Perform a series of operations:\n",
        "\n",
        "○ z = x**2 + 2x + 3\n",
        "\n",
        "○ Call z.backward() and print gradients"
      ],
      "metadata": {
        "id": "vsrpbRWtrMs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z=x**2+2*x+3\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sqB9qecoJ5B",
        "outputId": "935f6a7b-989a-40ca-b56e-16a5ae7626d8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(38., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z.backward()"
      ],
      "metadata": {
        "id": "qLfa1h3boZkr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDJnwZrzofzA",
        "outputId": "9df1213e-c001-42b5-84b6-312177d3b6a8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(12.)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I performed a mathematical operation on x to calculate z.\n",
        " It builds a computation graph in the background, which links x to z, so that it knows how z depends on x. This is useful because now we can go backward from z to x and compute gradients.I called z.backward() to compute the gradient of z with respect to x. This means PyTorch will now figure out how much z changes when x changes.\n",
        "\n"
      ],
      "metadata": {
        "id": "2Os8aJAq1LxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Try .detach() and explain its purpose\n",
        "\n"
      ],
      "metadata": {
        "id": "_-U2aGBvq2-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y=torch.tensor(3.0,requires_grad=True)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiqYXLqYseQm",
        "outputId": "47f60c4d-1a8f-4ecd-e01a-b8f85e92fd09"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3., requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp=xyz.detach()\n",
        "temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uMVvPRmtCL2",
        "outputId": "a6f298b9-078d-483f-cc07-afece5a73550"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(temp.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5IfWSKc2exC",
        "outputId": "61fb5c6f-8124-446c-9033-e26a709f196f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The .detach() function is used when you want to stop a tensor from tracking gradients. It's useful when you want to use a tensor for computation but not include it in gradient calculations, especially during evaluation or debugging.\n",
        " After detaching, the new tensor  will have the same value as y, but it doesn’t require gradients anymore. It’s cut off from the computation graph."
      ],
      "metadata": {
        "id": "X2fCJJla3HD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  temp2 = x ** 2\n",
        "print(temp2.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQWbYbO1vbyt",
        "outputId": "e960cd14-912a-4dae-b71d-1543dd67da85"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "when you want to disable gradient tracking globally like during prediction, where you don’t need to compute gradients. This saves memory and computation..Everything inside the with block is excluded from gradient tracking."
      ],
      "metadata": {
        "id": "j3uSZCh3413Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QjGP_W34zgd",
        "outputId": "fab96ddb-739e-4c0d-e471-d079cdf9deea"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchviz) (2.6.0+cu124)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from torchviz) (0.21)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torchviz)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torchviz)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torchviz)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torchviz)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torchviz)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torchviz)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchviz) (3.0.2)\n",
            "Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchviz\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchviz-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchviz import make_dot"
      ],
      "metadata": {
        "id": "OhrxoEW-3nOy"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_dot(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "wgVGLfI35lJw",
        "outputId": "3135cb3f-e2e8-4450-f899-5d0f46939de7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"204pt\" height=\"326pt\"\n viewBox=\"0.00 0.00 204.00 326.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 322)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-322 200,-322 200,4 -4,4\"/>\n<!-- 140387337438032 -->\n<g id=\"node1\" class=\"node\">\n<title>140387337438032</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"124.5,-31 70.5,-31 70.5,0 124.5,0 124.5,-31\"/>\n<text text-anchor=\"middle\" x=\"97.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 140387337531456 -->\n<g id=\"node2\" class=\"node\">\n<title>140387337531456</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"142,-86 53,-86 53,-67 142,-67 142,-86\"/>\n<text text-anchor=\"middle\" x=\"97.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 140387337531456&#45;&gt;140387337438032 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140387337531456&#45;&gt;140387337438032</title>\n<path fill=\"none\" stroke=\"black\" d=\"M97.5,-66.79C97.5,-60.07 97.5,-50.4 97.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"101,-41.19 97.5,-31.19 94,-41.19 101,-41.19\"/>\n</g>\n<!-- 140387337533760 -->\n<g id=\"node3\" class=\"node\">\n<title>140387337533760</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"142,-141 53,-141 53,-122 142,-122 142,-141\"/>\n<text text-anchor=\"middle\" x=\"97.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 140387337533760&#45;&gt;140387337531456 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140387337533760&#45;&gt;140387337531456</title>\n<path fill=\"none\" stroke=\"black\" d=\"M97.5,-121.75C97.5,-114.8 97.5,-104.85 97.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"101,-96.09 97.5,-86.09 94,-96.09 101,-96.09\"/>\n</g>\n<!-- 140387337530256 -->\n<g id=\"node4\" class=\"node\">\n<title>140387337530256</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"89,-196 0,-196 0,-177 89,-177 89,-196\"/>\n<text text-anchor=\"middle\" x=\"44.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 140387337530256&#45;&gt;140387337533760 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140387337530256&#45;&gt;140387337533760</title>\n<path fill=\"none\" stroke=\"black\" d=\"M53.25,-176.75C60.97,-169.03 72.4,-157.6 81.72,-148.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"84.31,-150.64 88.91,-141.09 79.36,-145.69 84.31,-150.64\"/>\n</g>\n<!-- 140387337526464 -->\n<g id=\"node5\" class=\"node\">\n<title>140387337526464</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148,-251 47,-251 47,-232 148,-232 148,-251\"/>\n<text text-anchor=\"middle\" x=\"97.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140387337526464&#45;&gt;140387337530256 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140387337526464&#45;&gt;140387337530256</title>\n<path fill=\"none\" stroke=\"black\" d=\"M88.75,-231.75C81.03,-224.03 69.6,-212.6 60.28,-203.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"62.64,-200.69 53.09,-196.09 57.69,-205.64 62.64,-200.69\"/>\n</g>\n<!-- 140387337524448 -->\n<g id=\"node7\" class=\"node\">\n<title>140387337524448</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"196,-196 107,-196 107,-177 196,-177 196,-196\"/>\n<text text-anchor=\"middle\" x=\"151.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 140387337526464&#45;&gt;140387337524448 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140387337526464&#45;&gt;140387337524448</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106.42,-231.75C114.28,-224.03 125.93,-212.6 135.42,-203.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"138.06,-205.59 142.75,-196.09 133.16,-200.6 138.06,-205.59\"/>\n</g>\n<!-- 140387337996816 -->\n<g id=\"node6\" class=\"node\">\n<title>140387337996816</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"124.5,-318 70.5,-318 70.5,-287 124.5,-287 124.5,-318\"/>\n<text text-anchor=\"middle\" x=\"97.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 140387337996816&#45;&gt;140387337526464 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140387337996816&#45;&gt;140387337526464</title>\n<path fill=\"none\" stroke=\"black\" d=\"M97.5,-286.92C97.5,-279.22 97.5,-269.69 97.5,-261.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"101,-261.25 97.5,-251.25 94,-261.25 101,-261.25\"/>\n</g>\n<!-- 140387337524448&#45;&gt;140387337533760 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140387337524448&#45;&gt;140387337533760</title>\n<path fill=\"none\" stroke=\"black\" d=\"M142.58,-176.75C134.72,-169.03 123.07,-157.6 113.58,-148.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"115.84,-145.6 106.25,-141.09 110.94,-150.59 115.84,-145.6\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7fae797da590>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For  visualizing the backward graph we use  the torchviz library to  understand how PyTorch tracks operations. First, install torchvizhis using !pip install torchvis will create a PNG image showing the computation graph it helps you  to understand the flow.\n",
        "\n"
      ],
      "metadata": {
        "id": "mcYYn7Bb3nAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Write your own custom backward pass for a small computation graph\n"
      ],
      "metadata": {
        "id": "vmQv7-PL6YnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward pass\n",
        "w = torch.tensor(5.0,requires_grad=True) # input\n",
        "y = w ** 2\n",
        "\n",
        "# Backward pass\n",
        "grad_y = 1.0                 # dy/dy = 1, seed for backprop\n",
        "grad_w = 2 * x * grad_y      # dy/dx = 2x\n",
        "\n",
        "# Results\n",
        "print(\"Input x:\", x)\n",
        "print(\"Output y = x^2:\", y)\n",
        "print(\"Gradient dy/dx:\", grad_w)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpyGjCKkFYsq",
        "outputId": "b436c47a-4e05-4f69-9104-7e826ae5f859"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input x: 5.0\n",
            "Output y = x^2: tensor(25., grad_fn=<PowBackward0>)\n",
            "Gradient dy/dx: 10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Training Pipeline Basics"
      ],
      "metadata": {
        "id": "5-Wshyr169ys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Create a custom dataset using torch.utils.data.Dataset."
      ],
      "metadata": {
        "id": "wywq1oq6D7y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class DummyDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        # Create 100 samples of random input and target values\n",
        "        self.x = torch.randn(100, 1)  # input feature\n",
        "        self.y = 9 * self.x + 3      # target with a known linear relation\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "OH5aN__I69ia"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " I created a custom dataset class by inheriting from torch.utils.data.Dataset. This allows you to define how your data is stored and how to access individual samples."
      ],
      "metadata": {
        "id": "Iy-ExzsvEFjV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Use DataLoader to iterate over data in batches"
      ],
      "metadata": {
        "id": "hiuXLbTrEnT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "dataset = DummyDataset()\n",
        "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)"
      ],
      "metadata": {
        "id": "FgVvRvotEVVu"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The DataLoader wraps our dataset and allows us to load data in mini-batches, which is much more efficient than loading one sample at a time.This will load 10 samples at a time in random order."
      ],
      "metadata": {
        "id": "IAm4RPmNEglV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define a simple neural network using nn.Module"
      ],
      "metadata": {
        "id": "PXGm7gA9Esp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Simplenn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Simplenn, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)  # 1 input → 1 output\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n"
      ],
      "metadata": {
        "id": "dJ0jov90Elm6"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I defined a basic neural network using nn.Module. For this example, I created a small model with a single nn.Linear layer that maps input x to output y.This model will try to learn the relationship between input x and output y."
      ],
      "metadata": {
        "id": "AY38a5wsFNlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Implement a training loop with:\n",
        "○ Forward pass\n",
        "○ Loss calculation (e.g., MSELoss or CrossEntropyLoss)\n",
        "○ Backward pass using .backward()\n",
        "○ Optimizer step"
      ],
      "metadata": {
        "id": "auqVFwbsEtrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleModel()\n",
        "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "_tmPsNKLFB3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training loop includes:\n",
        "\n",
        "Forward pass: Predict outputs.\n",
        "\n",
        "Loss calculation: Measure how wrong predictions are.\n",
        "\n",
        "Backward pass: Compute gradients with .backward().\n",
        "\n",
        "Optimizer step: Adjust model weights."
      ],
      "metadata": {
        "id": "W1B9gDSpFJtr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Train the model on dummy data for a few epochs and print the loss.\n"
      ],
      "metadata": {
        "id": "aF3cci-uEwYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    total_loss = 0\n",
        "    for batch_x, batch_y in dataloader:\n",
        "        # Forward pass\n",
        "        outputs = model(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "Gi_XpaPeFEUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I trained the model using the dummy dataset for 5 epochs. Each epoch means passing through the entire dataset once. During training, I printed the loss to monitor how well the model is learning."
      ],
      "metadata": {
        "id": "--D4uy_VFD-G"
      }
    }
  ]
}